{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This notebook was used to compile all of the available data from the Utah Flux Network stations.  It should only need to be used once, as other notebooks are used to comile the newer data.",
   "id": "8e6cb5d9c8ae57b4"
  },
  {
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T20:04:24.166323Z",
     "iopub.status.busy": "2024-10-01T20:04:24.166323Z",
     "iopub.status.idle": "2024-10-01T20:04:27.390335Z",
     "shell.execute_reply": "2024-10-01T20:04:27.390335Z",
     "shell.execute_reply.started": "2024-10-01T20:04:24.166323Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-27T05:12:44.656905Z",
     "start_time": "2024-12-27T05:12:41.768635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import urllib\n",
    "import sys\n",
    "import pathlib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from urllib.parse import quote\n",
    "from sqlalchemy import create_engine\n",
    "import configparser\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "#import pingouin as pg\n",
    "import plotly.express as px\n",
    "\n",
    "from micromet import AmerifluxDataProcessor\n",
    "\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "61e3a29165852b08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T20:04:27.394344Z",
     "iopub.status.busy": "2024-10-01T20:04:27.391341Z",
     "iopub.status.idle": "2024-10-01T20:04:28.485295Z",
     "shell.execute_reply": "2024-10-01T20:04:28.485295Z",
     "shell.execute_reply.started": "2024-10-01T20:04:27.394344Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-27T05:12:45.545959Z",
     "start_time": "2024-12-27T05:12:45.533578Z"
    }
   },
   "source": [
    "sys.path.append(\"//\")\n",
    "#sys.path.append(\"../../Micromet\")\n",
    "import micromet\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "config = configparser.ConfigParser()\n",
    "\n",
    "config.read('../../secrets/config.ini')\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import urllib.parse\n",
    "host = config['DEFAULT']['ip']\n",
    "pw = config['DEFAULT']['pw']\n",
    "user = config['DEFAULT']['login']\n",
    "\n",
    "encoded_password = urllib.parse.quote_plus(pw)\n",
    "\n",
    "def postconn_et(encoded_password, host='localhost',user='postgres',port='5432',db='groundwater', schema = 'groundwater'):\n",
    "    connection_text = \"postgresql+psycopg2://{:}:{:}@{:}:{:}/{:}?gssencmode=disable\".format(user,encoded_password,host,port,db)\n",
    "    return create_engine(connection_text, connect_args={'options': '-csearch_path={}'.format(schema)})\n",
    "\n",
    "\n",
    "engine = postconn_et(encoded_password, host=host, user=user)"
   ],
   "id": "fddcebdfd6a7b51c"
  },
  {
   "cell_type": "code",
   "id": "ad20f401f01ce92f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-01T14:09:27.572520Z",
     "iopub.status.busy": "2024-10-01T14:09:27.572520Z",
     "iopub.status.idle": "2024-10-01T14:09:27.607540Z",
     "shell.execute_reply": "2024-10-01T14:09:27.607540Z",
     "shell.execute_reply.started": "2024-10-01T14:09:27.572520Z"
    },
    "ExecuteTime": {
     "end_time": "2024-12-27T05:13:02.325931Z",
     "start_time": "2024-12-27T05:12:58.939572Z"
    }
   },
   "source": [
    "site_folders = {'US-UTD':'Dugout_Ranch',\n",
    "                'US-UTB':'BSF',\n",
    "                'US-UTJ':'Bluff',\n",
    "                'US-UTW':'Wellington',\n",
    "                'US-UTE':'Escalante',\n",
    "                'US-UTM':'Matheson',\n",
    "                'US-UTP':'Phrag',\n",
    "                'US-CdM':'Cedar_mesa',\n",
    "                'US-UTV':'Desert_View_Myton',\n",
    "                'US-UTN':'Juab'\n",
    "                }\n",
    "\n",
    "\n",
    "compdf = {}\n",
    "\n",
    "am = micromet.AmerifluxDataProcessor()\n",
    "\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    print(key)\n",
    "    raw_fold = pathlib.Path('H:/UGS_Flux/Data_Downloads/')\n",
    "    raw_data = am.raw_file_compile(raw_fold, value, search_str = \"*Flux_AmeriFluxFormat*.dat\")\n",
    "    if raw_data is not None:\n",
    "        am_data = micromet.Reformatter(raw_data, data_path=\"C:/Users/paulinkenbrandt/Documents/GitHub/MicroMet/data/extreme_values.csv\")\n",
    "        am_df = am_data.et_data\n",
    "        compdf[key] = am_df\n",
    "\n",
    "        am_df.to_csv(f\"../../station_data/{key}_HH_{am_df['TIMESTAMP_START'].values[0]:}_{am_df['TIMESTAMP_END'].values[-1]:}.csv\")\n",
    "        #am_df['stationid'] = key\n",
    "        \n",
    "        #am_df.to_sql('amfluxeddy', key, engine, if_exists='append',schema='groundwater')\n",
    "        \n",
    "cdf = pd.concat(compdf,axis=0)\n",
    "cdf.index.set_names(['stationid','datetime_start'],inplace=True)\n",
    "#cdf.rename(columns={'level_0':'stationid'},inplace=True)\n",
    "#cdf.to_parquet('../station_data/all_data.parquet')\n",
    "for col in cdf.columns:\n",
    "    cdf.rename(columns={col:col.lower()},inplace=True)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-UTD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:778: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  .interpolate(method=\"linear\", limit=1)  # Fill up to 30-minute gaps\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m raw_data \u001B[38;5;241m=\u001B[39m am\u001B[38;5;241m.\u001B[39mraw_file_compile(raw_fold, value, search_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m*Flux_AmeriFluxFormat*.dat\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m raw_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 24\u001B[0m     am_data \u001B[38;5;241m=\u001B[39m \u001B[43mmicromet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mReformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC:/Users/paulinkenbrandt/Documents/GitHub/MicroMet/data/extreme_values.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m     am_df \u001B[38;5;241m=\u001B[39m am_data\u001B[38;5;241m.\u001B[39met_data\n\u001B[0;32m     26\u001B[0m     compdf[key] \u001B[38;5;241m=\u001B[39m am_df\n",
      "File \u001B[1;32m~\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:606\u001B[0m, in \u001B[0;36mReformatter.__init__\u001B[1;34m(self, et_data, drop_soil, data_path, outlier_remove)\u001B[0m\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39met_data\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m    605\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcol\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 606\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumn range: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43met_data\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    607\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMO_LENGTH\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRECORD\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[0;32m    608\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39met_data[col] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_numeric(\n\u001B[0;32m    609\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39met_data[col], downcast\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minteger\u001B[39m\u001B[38;5;124m\"\u001B[39m, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    610\u001B[0m         )\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2899\u001B[0m, in \u001B[0;36mmax\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m   2781\u001B[0m \u001B[38;5;129m@array_function_dispatch\u001B[39m(_max_dispatcher)\n\u001B[0;32m   2782\u001B[0m \u001B[38;5;129m@set_module\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   2783\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue, initial\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue,\n\u001B[0;32m   2784\u001B[0m          where\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39m_NoValue):\n\u001B[0;32m   2785\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2786\u001B[0m \u001B[38;5;124;03m    Return the maximum of an array or maximum along an axis.\u001B[39;00m\n\u001B[0;32m   2787\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2897\u001B[0m \u001B[38;5;124;03m    5\u001B[39;00m\n\u001B[0;32m   2898\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_wrapreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaximum\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   2900\u001B[0m \u001B[43m                          \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:84\u001B[0m, in \u001B[0;36m_wrapreduction\u001B[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001B[0m\n\u001B[0;32m     82\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m reduction(axis\u001B[38;5;241m=\u001B[39maxis, dtype\u001B[38;5;241m=\u001B[39mdtype, out\u001B[38;5;241m=\u001B[39mout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n\u001B[0;32m     83\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 84\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mreduction\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpasskwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ufunc\u001B[38;5;241m.\u001B[39mreduce(obj, axis, dtype, out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpasskwargs)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\series.py:6517\u001B[0m, in \u001B[0;36mSeries.max\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m   6509\u001B[0m \u001B[38;5;129m@doc\u001B[39m(make_doc(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m\"\u001B[39m, ndim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m   6510\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(\n\u001B[0;32m   6511\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   6515\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   6516\u001B[0m ):\n\u001B[1;32m-> 6517\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mNDFrame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\generic.py:12404\u001B[0m, in \u001B[0;36mNDFrame.max\u001B[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12397\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmax\u001B[39m(\n\u001B[0;32m  12398\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m  12399\u001B[0m     axis: Axis \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m  12402\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m  12403\u001B[0m ):\n\u001B[1;32m> 12404\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stat_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  12405\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m  12406\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnanops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnanmax\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  12407\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  12408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  12409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  12410\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m  12411\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001B[0m, in \u001B[0;36mNDFrame._stat_function\u001B[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001B[0m\n\u001B[0;32m  12373\u001B[0m nv\u001B[38;5;241m.\u001B[39mvalidate_func(name, (), kwargs)\n\u001B[0;32m  12375\u001B[0m validate_bool_kwarg(skipna, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskipna\u001B[39m\u001B[38;5;124m\"\u001B[39m, none_allowed\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m> 12377\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reduce\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m  12378\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnumeric_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnumeric_only\u001B[49m\n\u001B[0;32m  12379\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001B[0m, in \u001B[0;36mSeries._reduce\u001B[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001B[0m\n\u001B[0;32m   6452\u001B[0m     \u001B[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001B[39;00m\n\u001B[0;32m   6453\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m   6454\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not allow \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkwd_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumeric_only\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6455\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwith non-numeric dtypes.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   6456\u001B[0m     )\n\u001B[1;32m-> 6457\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdelegate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001B[0m, in \u001B[0;36mbottleneck_switch.__call__.<locals>.f\u001B[1;34m(values, axis, skipna, **kwds)\u001B[0m\n\u001B[0;32m    145\u001B[0m         result \u001B[38;5;241m=\u001B[39m alt(values, axis\u001B[38;5;241m=\u001B[39maxis, skipna\u001B[38;5;241m=\u001B[39mskipna, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    146\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 147\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43malt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001B[0m, in \u001B[0;36m_datetimelike_compat.<locals>.new_func\u001B[1;34m(values, axis, skipna, mask, **kwargs)\u001B[0m\n\u001B[0;32m    401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike \u001B[38;5;129;01mand\u001B[39;00m mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    402\u001B[0m     mask \u001B[38;5;241m=\u001B[39m isna(values)\n\u001B[1;32m--> 404\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskipna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipna\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m datetimelike:\n\u001B[0;32m    407\u001B[0m     result \u001B[38;5;241m=\u001B[39m _wrap_results(result, orig_values\u001B[38;5;241m.\u001B[39mdtype, fill_value\u001B[38;5;241m=\u001B[39miNaT)\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\pandas\\core\\nanops.py:1098\u001B[0m, in \u001B[0;36m_nanminmax.<locals>.reduction\u001B[1;34m(values, axis, skipna, mask)\u001B[0m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _na_for_min_count(values, axis)\n\u001B[0;32m   1095\u001B[0m values, mask \u001B[38;5;241m=\u001B[39m _get_values(\n\u001B[0;32m   1096\u001B[0m     values, skipna, fill_value_typ\u001B[38;5;241m=\u001B[39mfill_value_typ, mask\u001B[38;5;241m=\u001B[39mmask\n\u001B[0;32m   1097\u001B[0m )\n\u001B[1;32m-> 1098\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeth\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m result \u001B[38;5;241m=\u001B[39m _maybe_null_out(result, axis, mask, values\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\_core\\_methods.py:44\u001B[0m, in \u001B[0;36m_amax\u001B[1;34m(a, axis, out, keepdims, initial, where)\u001B[0m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_amax\u001B[39m(a, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, out\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, keepdims\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     43\u001B[0m           initial\u001B[38;5;241m=\u001B[39m_NoValue, where\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m---> 44\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mumr_maximum\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeepdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwhere\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: '>=' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T04:57:40.724091Z",
     "start_time": "2024-12-27T04:56:53.478810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "site_folders = {'US-UTD':'Dugout_Ranch',\n",
    "                'US-UTB':'BSF',\n",
    "                'US-UTJ':'Bluff',\n",
    "                'US-UTW':'Wellington',\n",
    "                'US-UTE':'Escalante',\n",
    "                'US-UTM':'Matheson',\n",
    "                'US-UTP':'Phrag',\n",
    "                'US-CdM':'Cedar_mesa',\n",
    "                'US-UTV':'Desert_View_Myton',\n",
    "                'US-UTN':'Juab'\n",
    "                }\n",
    "\n",
    "\n",
    "compdf = {}\n",
    "\n",
    "am = micromet.AmerifluxDataProcessor()\n",
    "\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    print(key)\n",
    "    raw_fold = pathlib.Path('H:/UGS_Flux/Data_Downloads/')\n",
    "    raw_data = am.raw_file_compile(raw_fold, value, search_str = \"*Flux_AmeriFluxFormat*.dat\")\n",
    "    if raw_data is not None:\n",
    "        am_data = micromet.Reformatter(raw_data, data_path=\"C:/Users/paulinkenbrandt/Documents/GitHub/MicroMet/data/extreme_values.csv\")\n",
    "        am_df = am_data.et_data\n",
    "        compdf[key] = am_df\n",
    "        #am_df['stationid'] = key\n",
    "\n",
    "        #am_df.to_sql('amfluxeddy', key, engine, if_exists='append',schema='groundwater')\n",
    "\n",
    "cdf = pd.concat(compdf,axis=0)\n",
    "cdf.index.set_names(['stationid','datetime_start'],inplace=True)\n",
    "#cdf.rename(columns={'level_0':'stationid'},inplace=True)\n",
    "#cdf.to_parquet('../station_data/all_data.parquet')\n",
    "for col in cdf.columns:\n",
    "    cdf.rename(columns={col:col.lower()},inplace=True)\n"
   ],
   "id": "1b2227e2487e1f63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-UTD\n",
      "US-UTB\n",
      "US-UTJ\n",
      "US-UTW\n",
      "US-UTE\n",
      "US-UTM\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\d20211228\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\d20220215\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Matheson\\d20220323\\8442_Flux_AmeriFluxFormat_0.dat\n",
      "US-UTP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US-CdM\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Cedar_mesa\\met_20241008\\45027_Flux_AmeriFluxFormat_6.dat\n",
      "US-UTV\n",
      "US-UTN\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Juab\\20210622_farm\\8441_Flux_AmeriFluxFormat_4.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Juab\\combined_farm\\8441_Flux_AmeriFluxFormat_4.dat\n",
      "Unknown header format for file: H:\\UGS_Flux\\Data_Downloads\\Juab\\20210826_farmNephi\\20210826\\8441_Flux_AmeriFluxFormat_11.dat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n",
      "C:\\Users\\paulinkenbrandt\\Anaconda3\\envs\\pygis12\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2035: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\paulinkenbrandt\\Documents\\GitHub\\MicroMet\\micromet\\converter.py:944: RuntimeWarning: Mean of empty slice\n",
      "  avg = np.nanmean(arr)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T05:01:58.442720Z",
     "start_time": "2024-12-27T05:01:58.432323Z"
    }
   },
   "cell_type": "code",
   "source": "am_df[['file_no','TIMESTAMP_START','TIMESTAMP_END']]",
   "id": "88e9186bac4325e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                     file_no  TIMESTAMP_START  TIMESTAMP_END\n",
       "datetime_start                                              \n",
       "2018-08-22 10:00:00  -9999.0     201808221000   201808221030\n",
       "2018-08-22 10:30:00      8.0     201808221030   201808221100\n",
       "2018-08-22 11:00:00      8.0     201808221100   201808221130\n",
       "2018-08-22 11:30:00      8.0     201808221130   201808221200\n",
       "2018-08-22 12:00:00      8.0     201808221200   201808221230\n",
       "...                      ...              ...            ...\n",
       "2024-05-09 08:30:00      8.0     202405090830   202405090900\n",
       "2024-05-09 09:00:00      8.0     202405090900   202405090930\n",
       "2024-05-09 09:30:00      8.0     202405090930   202405091000\n",
       "2024-05-09 10:00:00      8.0     202405091000   202405091030\n",
       "2024-05-09 10:30:00      8.0     202405091030   202405091100\n",
       "\n",
       "[100178 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_no</th>\n",
       "      <th>TIMESTAMP_START</th>\n",
       "      <th>TIMESTAMP_END</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_start</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-08-22 10:00:00</th>\n",
       "      <td>-9999.0</td>\n",
       "      <td>201808221000</td>\n",
       "      <td>201808221030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 10:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221030</td>\n",
       "      <td>201808221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 11:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221100</td>\n",
       "      <td>201808221130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 11:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221130</td>\n",
       "      <td>201808221200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-22 12:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>201808221200</td>\n",
       "      <td>201808221230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 08:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405090830</td>\n",
       "      <td>202405090900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 09:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405090900</td>\n",
       "      <td>202405090930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 09:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405090930</td>\n",
       "      <td>202405091000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 10:00:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405091000</td>\n",
       "      <td>202405091030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-09 10:30:00</th>\n",
       "      <td>8.0</td>\n",
       "      <td>202405091030</td>\n",
       "      <td>202405091100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100178 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T06:02:12.041319Z",
     "start_time": "2024-12-27T06:02:06.307832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def file_compile(\n",
    "    raw_fold: Path,\n",
    "    station_folder_name: Path,\n",
    "    search_str=\"*Flux_AmeriFluxFormat*.dat\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compiles raw AmeriFlux datalogger files into a single dataframe.\n",
    "\n",
    "    :param raw_fold: Path to the root folder of raw datalogger files\n",
    "    :type raw_fold: pathlib.Path\n",
    "    :param station_folder_name: Name of the station folder containing the raw datalogger files\n",
    "    :type station_folder_name: str\n",
    "    :return: Dataframe containing compiled AmeriFlux data, or None if no valid files found\n",
    "    :rtype: pandas.DataFrame or None\n",
    "    \"\"\"\n",
    "    amflux = {}\n",
    "    station_folder = raw_fold / station_folder_name\n",
    "\n",
    "\n",
    "    # iterate through specified folder of raw datalogger files (.dat); Match to AmeriFlux datalogger files\n",
    "    for file in station_folder.rglob(search_str):\n",
    "        # get the base number of the raw ameriflux file\n",
    "        baseno = file.name.split(\".\")[0]\n",
    "\n",
    "        try:\n",
    "            file_number = int(baseno.split(\"_\")[-1])\n",
    "        except:\n",
    "            file_number = 9999\n",
    "\n",
    "        if file_number >= 0:\n",
    "            try:\n",
    "                df = pd.read_csv(file,\n",
    "                                 skiprows=[1, 2],\n",
    "                                 usecols=[0,1],\n",
    "                                 na_values=[-9999,\"NAN\",\"NaN\"])\n",
    "            except:\n",
    "                df = None\n",
    "            if df is not None:\n",
    "                #print(df.columns[0])\n",
    "                # print(file)\n",
    "                if df.columns[0] ==  \"TIMESTAMP_START\":\n",
    "                    df[\"file_no\"] = file_number\n",
    "                    df[\"baseno\"] = baseno\n",
    "                    amflux[baseno] = df\n",
    "\n",
    "    if amflux:\n",
    "        # concat dataframes that were successfully read in\n",
    "        et_data = pd.concat(amflux, axis=0).reset_index()\n",
    "        #et_data = et_data.drop(columns=[\"level_0\", \"level_1\"])\n",
    "    else:\n",
    "        et_data = None\n",
    "    return et_data\n",
    "\n",
    "date_data = {}\n",
    "for key, value in site_folders.items():\n",
    "\n",
    "    #print(key)\n",
    "    raw_fold = pathlib.Path('H:/UGS_Flux/Data_Downloads/')\n",
    "    date_data[key] = file_compile(raw_fold, value, search_str = \"*Flux_AmeriFluxFormat*.dat\")\n",
    "\n",
    "df = pd.concat(date_data,axis=0)\n",
    "dfmod = df.drop(['level_0','level_1'],axis=1).reset_index().drop(['level_1'],axis=1).rename(columns={'level_0':'stationid'})#.set_index(['stationid','file_no'])\n",
    "dfmod['TIMESTAMP_START'] = dfmod['TIMESTAMP_START'].astype('int')\n",
    "dfmod['TIMESTAMP_END'] = dfmod['TIMESTAMP_END'].astype('int')\n",
    "dfmod.sort_values(['stationid','file_no'],inplace=True)\n",
    "\n",
    "def f(x):\n",
    "    d = {}\n",
    "    d['start_min'] = x['TIMESTAMP_START'].min()\n",
    "    d['start_max'] = x['TIMESTAMP_START'].max()\n",
    "    d['end_min'] = x['TIMESTAMP_END'].min()\n",
    "    d['end_max'] = x['TIMESTAMP_END'].max()\n",
    "\n",
    "    d['file'] = x['baseno'].values[0]\n",
    "    return pd.Series(d, index=d.keys())\n",
    "\n",
    "dstats = dfmod.groupby(['stationid','file_no']).apply(f)\n"
   ],
   "id": "183103312ced13cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\paulinkenbrandt\\AppData\\Local\\Temp\\1\\ipykernel_11876\\1203840080.py:79: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dstats = dfmod.groupby(['stationid','file_no']).apply(f)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T06:04:15.377605Z",
     "start_time": "2024-12-27T06:04:14.295211Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "192764b46d3f5910",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51bb65809614a82c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
